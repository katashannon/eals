---
title: "EALS Study 3 Analysis: Learning Strategies, Multifunction Box (turned on, 4 puzzles to solve)"
author: "Kat Adams Shannon"
date: "2025-05-23"
output:
  html_document:
    toc: true
    toc_depth: 3
    toc_float: true
---

```{r setup, include=T}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, 
                      message = FALSE, sanitize = TRUE)
```


```{r}
# load in required packages

#install.packages("devtools")
#devtools::install_github("maxlinde/baymedr") #run again if need to reinstall baymedr - this didn't work recently, so had to manually download and install...
# load in required packages
library(tidyverse)
library(survival)
library(ggsurvfit)
library(survminer)
library(baymedr)
library(kableExtra)
library(zoo)
library(patchwork)
library(pwr)
library(brms)
library(bridgesampling)
library(BFpack)
library(boot)
library(rstanarm)
library(robustbase)

```


# Project Overview

Preregistration:
- AsPredicted #184387

A note about data. These finalized data have been double-coded. Inter-rater reliability is reported and any large discrepancies were resolved in a third step by an expert coder blind to condition. More information about reliability and data cleaning is available on Github in the folder [XXXXXX fill in]

# Analytic goals

1. First we will run a cox regression/survival analysis testing the hypothesis of a negative effect of unreliable condition on children's help-seeking during the free play session (presence/absence of a bid for help , and time to first bid if present). 

> Data were collected until our preregistered stopping rule of either when 100 participants were included or September 30, 2024 end date was met, whichever came first. By Sept 30, 2024 our final N = 92.

2. In a modification of our preregistered analysis, we will test the hypothesis of a positive effect of unreliable condition on total time exploring during the free play session. We realize that our preregistered approach of using cox regression/survival analysis for the exploration DV was not statistically appropriate given this is a cumulative time measured across 3 minutes rather than the presence/absence of an event.

3. In a non-preregistered analysis, we will also test condition differences of two other exploration variables: number of causal mechanisms explored (out of 21 possible) and use of complex combinations (e.g., activating/engaging two causal mechanisms simultaneously)

4. In a preregistered analysis, we will test condition differences in total number of sides solved of novel toy (out of 4 possible)

5. Throughout, in a non-preregistered analysis, we will test at any significant condition effects by age and gender.


# Experiment 3

## Load and Prepare Data


```{r}
# Read the merged data file into R
eals3_n92_df <- read.csv("EALS_Study3_Data_N92.csv")

# Read the merged data file into R
eals3_n92_df <- read.csv("/Users/Kat/Library/Mobile Documents/com~apple~CloudDocs/EALS/Code/EALS final repo/data/exp3/EALS_Study3_Data_N92.csv")

```


```{r}
# Set factor level order for consistency across models and plots - so, reliable is reference group
eals3_n92_df$condition <- factor(eals3_n92_df$condition, levels = c("Reliable", "Unreliable"))
```


```{r}
#also create custom colors for plots
plot_colors <- c("Reliable" = "#268bd2", "Unreliable" = "#dc322f")
```

## Descriptives

First, let's get some descriptive statistics about the sample, age, gender, etc.

```{r}

summary_demo <- eals3_n92_df %>%
  group_by(condition) %>%
  summarise(
    count = n(),
    mean_age = mean(age_m, na.rm = TRUE),
    age_range = paste0(min(age_m, na.rm = TRUE), "-", max(age_m, na.rm = TRUE)),
    male_count = sum(gender_male1, na.rm = TRUE),
    female_count = sum(1 - gender_male1, na.rm = TRUE)
  )

print(summary_demo)
```

## Help-seeking analysis

Let's look at our help-seeking DV next. Note that we impute the maximum time of 180 seconds (i.e. across 3 min free play session) to account for missingness in the duration to first bid for help variable.

```{r}
# Impute missing help bids with 180s for survival analysis
subset_eals3_n92_df <- eals3_n92_df %>%
  mutate(first_help_bid.duration = ifelse(is.na(first_help_bid.duration), 180, first_help_bid.duration))

```

Let's also get help-seeking descriptives.

```{r}

# Compute descriptive statistics for first_help_bid.duration (only for participants who made a bid)
summary_first_help <- eals3_n92_df %>%
  filter(first_help_bid.count == 1) %>%  # including only those who made a bid for help
  group_by(condition) %>%
  summarise(
    mean_first_bid = mean(first_help_bid.duration, na.rm = TRUE), # in seconds from start of free play session
    sd_first_bid = sd(first_help_bid.duration, na.rm = TRUE),
    median_first_bid = median(first_help_bid.duration, na.rm = TRUE),
    min_first_bid = min(first_help_bid.duration, na.rm = TRUE),
    max_first_bid = max(first_help_bid.duration, na.rm = TRUE)
  )

# Compute total participants and percentage who made a bid for help
summary_bid_count <- eals3_n92_df %>%
  group_by(condition) %>%
  summarise(
    total_N = n(),  
    bid_N = sum(first_help_bid.count, na.rm = TRUE),  # count of participants who made a bid at all during free play session
    percent_bid = (bid_N / total_N) * 100  # percentage who made a bid
  )

# Merge summaries
summary_combined <- merge(summary_first_help, summary_bid_count, by = "condition")

print(summary_combined)

```

Onto our pre-registered analysis comparing presence/absence of a bid for help and duration of first bid for help by condition.

## Do children in the unreliable condition seek help less often and more slowly than their peers in the reliable condition (N = 92)?

```{r}
# prepare the survival analysis 
Surv(subset_eals3_n92_df$first_help_bid.duration, subset_eals3_n92_df$first_help_bid.count) 
```

```{r}
surv_model_eals3_n92 <- survfit(Surv(first_help_bid.duration, first_help_bid.count) ~ condition, data = subset_eals3_n92_df)
summary(surv_model_eals3_n92)
```

Now let's plot these Kaplan-Meier survival curves by condition:

```{r}

ggsurvplot(surv_model_eals3_n92, conf.int = TRUE, pval = TRUE, risk.table = TRUE,
           legend.labs = c("Reliable", "Unreliable"),
           legend.title = "Condition",
           palette = c("#268bd2", "#dc322f"),
           title = "Kaplan-Meier Curve for Time to First Bid for Help",
           xlab = "Time (s)",
           risk.table.height = 0.3)
```

## Survival Cox Regression


```{r}
cox_surv_model_eals3_n92 <- coxph(Surv(first_help_bid.duration, first_help_bid.count) ~ condition, data = subset_eals3_n92_df)

summary(cox_surv_model_eals3_n92)
```

## Bayes factor for survival analysis

Finally, let's compute a Bayes factor for a Cox proportional hazards regression model (this baymedr package does it for one dichotomous independent variable, here: condition).

```{r}
cox_model_eals3_n92 <- subset_eals3_n92_df %>%
  dplyr::select(first_help_bid.duration, first_help_bid.count, condition) %>%
  mutate(condition = if_else(condition == "Unreliable", 1, 0))
# note here: dummy coded Unreliable = 1 (test), Reliable = 0 (reference)

coxph_mod <- coxph_bf(data = cox_model_eals3_n92,
         null_value = 0,
         alternative = "one.sided",
         direction = "low", # H1: Unreliable has lower hazard than Reliable
         prior_mean = 0,
         prior_sd = 1)

coxph_mod
```

In sum, we do see a significant condition difference. Children in the unreliable condition are less likely to make a bid for help/slower to make a bid for help than their peers in the reliable condition, p = 0.027, BF = 5.3.

Since we found a condition difference, we will next look at the model with age and gender covariates.

## Survival analysis with covariates added 

```{r}
# Fit Cox model with condition, age, and gender as predictors
cox_model_eals3_n92_cov <- coxph(Surv(first_help_bid.duration, first_help_bid.count) ~ 
                        condition + age_m + gender_male1, 
                        data = subset_eals3_n92_df)

# Display model summary
summary(cox_model_eals3_n92_cov)

```
Unreliable condition has a significant negative effect on help-seeking. Age and gender not significant predictors.

## Exploration Analysis

Do we see a condition difference in total time exploring during the 3 min free play session?

Let's start with descriptive statistics for total time exploring (max 180 seconds possible).

Note that our exploration variable for Experiment 3 is named toy_exploration.nooverlap.duration.sum. Because children could interact with multiple sides of the puzzle simultaneously, we calculated the total exploration time in a way that avoids double-counting overlapping time intervals.

```{r}
# descriptive statistics for toy_exploration.nooverlap.duration.sum by condition
summary_toy_exploration <- eals3_n92_df %>%
  group_by(condition) %>%
  summarise(
    mean_toy_exploration = mean(toy_exploration.nooverlap.duration.sum, na.rm = TRUE),
    sd_toy_exploration = sd(toy_exploration.nooverlap.duration.sum, na.rm = TRUE),
    median_toy_exploration = median(toy_exploration.nooverlap.duration.sum, na.rm = TRUE),
    min_toy_exploration = min(toy_exploration.nooverlap.duration.sum, na.rm = TRUE),
    max_toy_exploration = max(toy_exploration.nooverlap.duration.sum, na.rm = TRUE),
    count_toy_exploration = n() # number of participants per condition
  )

print(summary_toy_exploration)

```
## Boxplot total time exploring

Let's next visualize total time spent exploring by condition for descriptive purposes.

```{r}
#boxplot with jitter 

ggplot(eals3_n92_df, aes(x = condition, y = toy_exploration.nooverlap.duration.sum, fill = condition)) +
  geom_boxplot(alpha = 0.6, outlier.shape = NA, width = 0.5) +
  geom_jitter(aes(color = condition), width = 0.2, size = 2, alpha = 0.7) +  # jitter points colored by condition
  scale_fill_manual(values = plot_colors) +
  scale_color_manual(values = plot_colors) +
  scale_y_continuous(breaks = seq(0, 180, by = 30), limits = c(0, 181)) +  # note have 181 as max to include values at max time 180 seconds
  theme_minimal() +
  theme(legend.position = "none", axis.text.x = element_text(size = 14)) +  # remove legend & increase x-axis font size
  labs(title = "Exploration Time by Condition",
       x = "Condition",
       y = "Total Time Exploring (s)")
```

## Wilcoxon rank-sum test total time exploring

Next, let's test condition differences in total time exploring the 4-button box using a wilcoxon rank-sum test.

```{r}
# subset data by condition
reliable_data <- eals3_n92_df[eals3_n92_df$condition == "Reliable", "toy_exploration.nooverlap.duration.sum"]
unreliable_data <- eals3_n92_df[eals3_n92_df$condition == "Unreliable", "toy_exploration.nooverlap.duration.sum"]

# wilcoxon rank-sum test 
wilcox_test_eals3_n92 <- wilcox.test(reliable_data, unreliable_data, exact = FALSE)

print("Variable: toy_exploration.nooverlap.duration.sum")
print(wilcox_test_eals3_n92)
```
The results of the wilcoxon rank-sum test show a significant condition difference in overall time spent exploring the box. Children in the unreliable condition explored significantly longer across the 3 minutes of free play than their peers in the reliable condition, p = 0.04.

Since we found a significant condition effect, we will also look at the model with age and gender added as covariates. 

## Total time exploring with covariates

Let's take one more look at the distribution by condition for total time spent exploring.

```{r}
# Plot histogram with fitted distribution lines for total time spent exploring
plot_dur_explore <- ggplot(eals3_n92_df, aes_string(x = "toy_exploration.nooverlap.duration.sum", fill = "condition")) +
  geom_histogram(aes(y = ..density..), bins = 30, alpha = 0.7, position = "dodge") +
  geom_density(aes_string(color = "condition"), fill = NA, size = 1, position = "identity") +
  scale_fill_manual(values = plot_colors) +
  scale_color_manual(values = plot_colors) +
  labs(title = paste("Time spent exploring in toy task by condition")) +
  theme_minimal()

print(plot_dur_explore)
```

Our distribution for time spent exploring is right-skewed, so first we will look at the fit of a log transformation (log(x + 1) to handle 0s) vs. the raw data for our model with covariates.

```{r}
model_raw <- lm(toy_exploration.nooverlap.duration.sum ~ age_m + condition, data = eals3_n92_df)

eals3_n92_df <- eals3_n92_df %>%
  mutate(log_explore = log(toy_exploration.nooverlap.duration.sum + 1))

model_log <- lm(log_explore ~ age_m + condition, data = eals3_n92_df)

par(mfrow = c(2, 2))
plot(model_raw, main = "Raw Outcome")
plot(model_log, main = "Log-Transformed Outcome")
```


```{r}
shapiro.test(residuals(model_raw))
shapiro.test(residuals(model_log))
```

So, normality with the Shapiro-Wilks test looks a little worse with log transformation but Q-Q Plot and Heteroskedasticity visually look a little better. Let's take a look at outlier effects (note observation #44 in residuals vs. leverage plots above).


```{r}
model_log <- lm(log(toy_exploration.nooverlap.duration.sum + 1) ~ 
               condition + age_m + gender_male1, 
               data = eals3_n92_df)

# calculate Cook's distance
eals3_n92_df$cooks_d <- cooks.distance(model_log)

# view top influential points
head(eals3_n92_df[order(-eals3_n92_df$cooks_d), c("cooks_d", "toy_exploration.nooverlap.duration.sum", "condition", "age_m")], 5)

plot(model_log, which = 4)  # Cook's distance plot


```


Observation 44 shows a disproportionately high influence on the linear model with the log transformation (Cook’s D = 0.48). This participant’s data are valid and retained in all analyses. However, to ensure results were not unduly influenced by this case, we will use robust regression (MM-estimation) as our primary modeling approach with the log transformed data.

## Robust linear model predicting total time exploring with log transformation and covariates

```{r}

robust_model <- lmrob(log_explore ~ condition + age_m + gender_male1, data = eals3_n92_df)

# View summary
summary(robust_model)
confint(robust_model)
```


## Other Exploration Analysis (# Causal Functions and presence/absence complex combination)


```{r}
# Descriptive statistics for total_explored by condition
summary_total_explored <- eals3_n92_df %>%
  group_by(condition) %>%
  summarise(
    mean_total_explored = mean(total_explored, na.rm = TRUE),
    sd_total_explored = sd(total_explored, na.rm = TRUE),
    median_total_explored = median(total_explored, na.rm = TRUE),
    min_total_explored = min(total_explored, na.rm = TRUE),
    max_total_explored = max(total_explored, na.rm = TRUE),
    count_total_explored = sum(!is.na(total_explored)) # number of participants per condition
  )

print(summary_total_explored)

```
Let's visualize number of causal affordances explored by condition

```{r}
# Boxplot and jitter for total_explored (number of causal affordances explored, max = 21)
ggplot(eals3_n92_df, aes(x = condition, y = total_explored, fill = condition)) +
  geom_boxplot(alpha = 0.6, outlier.shape = NA, width = 0.5) +
  geom_jitter(aes(color = condition), width = 0.2, size = 2, alpha = 0.7) +
  scale_fill_manual(values = plot_colors) +
  scale_color_manual(values = plot_colors) +
  scale_y_continuous(breaks = seq(0, 21, by = 3), limits = c(0, 22)) +
  theme_minimal() +
  theme(legend.position = "none", axis.text.x = element_text(size = 14)) +
  labs(
    title = "Total Causal Affordances Explored by Condition",
    x = "Condition",
    y = "Number of Causal Affordances Explored"
  )

```

## Wilcoxon rank-sum test total causal affordances explored

Do children differ across conditions in how many of the 21 possible causal affordances they explore (i.e., make a state change like push a button/pull a cord, etc.)?

```{r}
# Run Wilcoxon test for total_explored
wilcox_test_eals3_n92_total_explored <- wilcox.test(
  total_explored ~ condition, 
  data = eals3_n92_df, 
  exact = FALSE
)

# Print the result for total_explored
print(wilcox_test_eals3_n92_total_explored)
```

We do find a significant difference such that those in the unreliable condition try more causal affordances that those in the reliable condition, p = 0.04.

## total causal affordances explored with covariates

So, let's check the model adding age and gender as covariates.

Since this is a count variable, let's fit a Poisson regression and assess outlier influence to determine whether a robust approach is warranted.

```{r}
poisson_model <- glm(
  total_explored ~ condition + age_m + gender_male1,
  family = poisson(link = "log"),
  data = eals3_n92_df
)

summary(poisson_model)
```

We find significant effects of condition (p = .049) and age (p < 0.001) in the poisson regression. For consistency with previous models, let's check for outlier influence:

```{r}

# influential observations
cooks_d <- cooks.distance(poisson_model)
plot(cooks_d, type = "h", main = "Cook's Distance (Poisson Model)")
abline(h = 4 / nrow(eals3_n92_df), col = "red", lty = 2)


```

Again, observation 44 appears disproportionately influential. We can also report a robust model:

## Robust glml predicting total causal affordances explored with covariates

```{r}
robust_poisson <- glmrob(
  total_explored ~ condition + age_m + gender_male1,
  family = poisson,
  data = eals3_n92_df
)
summary(robust_poisson)

```

Unreliable condition and older age are significants positive predictor of number of causal affordances explored.

## Complex combinations

Next we can look at presence/absence of using a complex combination (i.e., trying two or more causal mechanisms at once)

Let's visualize complex combo by condition

```{r}
# Calculate means and 95% confidence intervals for complex_combo by condition
mean_ci_complex_combo <- eals3_n92_df %>%
  filter(!is.na(complex_combo)) %>%  # Exclude NA values
  group_by(condition) %>%
  summarise(
    mean_complex_combo = mean(as.numeric(complex_combo), na.rm = TRUE) * 100,  # Convert to numeric if needed
    ci_lower = mean(as.numeric(complex_combo), na.rm = TRUE) * 100 - qt(0.975, df = n() - 1) * sd(as.numeric(complex_combo), na.rm = TRUE) / sqrt(n()) * 100,
    ci_upper = mean(as.numeric(complex_combo), na.rm = TRUE) * 100 + qt(0.975, df = n() - 1) * sd(as.numeric(complex_combo), na.rm = TRUE) / sqrt(n()) * 100
  )

# Plot the means with error bars for 95% confidence intervals
mean_ci_complex_combo_plot <- ggplot(mean_ci_complex_combo, aes(x = condition, y = mean_complex_combo, fill = condition)) +
  geom_bar(stat = "identity", position = position_dodge(), width = 0.7) +
  geom_errorbar(aes(ymin = ci_lower, ymax = ci_upper), position = position_dodge(0.7), width = 0.25) +
  scale_y_continuous(labels = scales::percent_format(scale = 1), limits = c(0, 100)) +
  labs(x = "Condition", y = "Mean Proportion of Complex Combo (%)", fill = "Condition") +
  scale_fill_manual(values = c("Unreliable" = "#dc322f", "Reliable" = "#268bd2")) +
  ggtitle("Mean Proportion of Complex Combo by Condition with 95% CI") +
  theme_minimal()

# Display the plot
print(mean_ci_complex_combo_plot)


```

## Logistic regression testing complex combinations

```{r}
# Run the logistic regression
logistic_model <- glm(complex_combo ~ condition, family = "binomial", data = eals3_n92_df)

# View the summary of the model
summary(logistic_model)

```

Results show that children in the unreliable condition are more likely to use a complex combination than their peers in the reliable condition during the 3 minute free play.

Given the significant condition effect, let's look at the model with covariates added.

## Complex combinations with covariates

```{r}
#add covariates
logistic_model_cov <- glm(
  complex_combo ~ condition + age_m + gender_male1,
  family = "binomial",
  data = eals3_n92_df
)

summary(logistic_model_cov)
```

Let's check for outlier influence again, for consistency across all models:

```{r}
cooks_d <- cooks.distance(logistic_model_cov)
plot(cooks_d, type = "h", main = "Cook's Distance (Logistic Model)")
abline(h = 4 / nrow(eals3_n92_df), col = "red", lty = 2)

```

No extreme outliers influencing the complex combination data.


##  Learning Outcome Analysis


Let's first look at the descriptives per puzzles side (out of 4 possible),


```{r}
# List of side variable names
solved_vars <- c("side1_solved_numeric", "side2_solved_numeric", 
                 "side3_solved_numeric", "side4_solved_numeric")

# Create empty list to store results
descriptive_stats_list <- list()

# Loop over variables
for (var in solved_vars) {
  descriptive_stats_list[[var]] <- eals3_n92_df %>%
    group_by(condition) %>%
    summarise(
      count = sum(!is.na(.data[[var]])),
      mean = mean(.data[[var]], na.rm = TRUE),
      sd = sd(.data[[var]], na.rm = TRUE),
      .groups = "drop"
    ) %>%
    mutate(variable = var, .before = 1)
}

# Combine all into a single table (optional)
descriptive_sides_solved <- bind_rows(descriptive_stats_list)

# View the result
descriptive_sides_solved

```

## bar chart total sides solved

Let's visualize proportion solved by condition for each of the 4 puzzles in a plot:

```{r}
# Helper function to compute mean and CI
compute_ci <- function(var, label) {
  eals3_n92_df %>%
    group_by(condition) %>%
    summarise(
      side = label,
      mean = mean(.data[[var]], na.rm = TRUE) * 100,
      ci_lower = mean(.data[[var]], na.rm = TRUE) * 100 - qt(0.975, df=n()-1) * sd(.data[[var]], na.rm = TRUE) / sqrt(n()) * 100,
      ci_upper = mean(.data[[var]], na.rm = TRUE) * 100 + qt(0.975, df=n()-1) * sd(.data[[var]], na.rm = TRUE) / sqrt(n()) * 100,
      .groups = "drop"
    )
}

# Apply to each side
mean_ci_side1 <- compute_ci("side1_solved_numeric", "Side 1")
mean_ci_side2 <- compute_ci("side2_solved_numeric", "Side 2")
mean_ci_side3 <- compute_ci("side3_solved_numeric", "Side 3")
mean_ci_side4 <- compute_ci("side4_solved_numeric", "Side 4")

# Combine into one dataframe
mean_ci_combined <- bind_rows(mean_ci_side1, mean_ci_side2, mean_ci_side3, mean_ci_side4)

# Base plot
base_plot <- ggplot(mean_ci_combined, aes(x = condition, y = mean, fill = condition)) +
  geom_bar(stat = "identity", position = position_dodge(), width = 0.7) +
  geom_errorbar(aes(ymin = pmax(ci_lower, 0), ymax = pmin(ci_upper, 100)), 
                position = position_dodge(0.7), width = 0.25) +
  scale_y_continuous(labels = scales::percent_format(scale = 1), limits = c(0, 100)) +
  labs(x = "Condition", y = "Mean Proportion Solving Puzzle (%)", fill = "Condition") +
  scale_fill_manual(values = c("Unreliable" = "#dc322f", "Reliable" = "#268bd2")) +
  ggtitle("Mean Proportion Solving Each Puzzle by Condition with 95% CI") +
  theme_minimal() +
  facet_wrap(~ side, ncol = 2)

# Handle CIs that extend beyond 0–100%
out_of_bounds_segments <- mean_ci_combined %>%
  filter(ci_lower < 0 | ci_upper > 100) %>%
  mutate(
    ymin_out = ifelse(ci_lower < 0, 0, NA),
    ymax_out = ifelse(ci_upper > 100, 100, NA)
  )

# Final plot with dashed segments
final_plot <- base_plot +
  geom_segment(data = out_of_bounds_segments, aes(x = condition, xend = condition, 
                                                  y = ymin_out, yend = pmin(ci_lower, 0)),
               color = "black", position = position_dodge(0.7), linetype = "dashed") +
  geom_segment(data = out_of_bounds_segments, aes(x = condition, xend = condition, 
                                                  y = ymax_out, yend = pmax(ci_upper, 100)),
               color = "black", position = position_dodge(0.7), linetype = "dashed")

# Display
final_plot

```


Let's also look at the descriptives for total sides solved

```{r}
descriptive_total_solved <- eals3_n92_df %>%
  group_by(condition) %>%
  summarise(
    count = sum(!is.na(total_solved)),
    mean = mean(total_solved, na.rm = TRUE),
    sd = sd(total_solved, na.rm = TRUE),
    .groups = "drop"
  ) %>%
  mutate(variable = "total_solved", .before = 1)

descriptive_total_solved

```

Let's test condition differences in number of sides solved

## logistic regression predicting total sides solved

```{r}
# maximum possible sides that can be solved is 4
max_sides <- 4 

# Create a 'failures' column
eals3_n92_df <- eals3_n92_df %>%
  mutate(failures = max_sides - total_solved)

# Run the logistic regression
logistic_model <- glm(cbind(total_solved, failures) ~ condition, 
                      family = binomial, data = eals3_n92_df)

# Summary of the model
summary(logistic_model)
```

We find no condition difference in total number of sides solved during free play session, p = 0.97

