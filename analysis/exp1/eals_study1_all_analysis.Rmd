---
title: 'EALS Study 1 Analysis: Puzzle Choice'
author: "Kat Adams Shannon"
date: "2025-05-23"
output:
  html_document:
    toc: true
    toc_depth: 3
    toc_float: true
---

```{r setup, include=T}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, 
                      message = FALSE, sanitize = TRUE)
```


```{r}
# load in required packages
library(tidyverse)
library(BFpack)
library(boot)
library(epitools)
library(papaja)
library(tinylabels)
```


# Project Overview

This markdown file documents the preregistered and exploratory analyses for Study 1 of the EALS project. It includes two experimental conditions:

- **V1**: Puzzles visible
- **V2**: Puzzles obscured

Preregistrations:
- V1: AsPredicted #89040
- V2: AsPredicted #103468

# Analytic goals

1. First we will run a logistic regression in the form of choice of `puzzle_harder ~ condition` (reliable/unreliable help). 

2. We will also generate Bayes factors for interpretation of the evidence of our hypothesis of a condition effect and for sequential sampling. 

> The sampling stopping criteria is: We will test an initial sample of 10 children in each condition, and then evaluate the Bayes Factor on the hypothesis of a negative condition effect (unreliable experimenter -> lower choice of hard puzzle) after each day of testing. We will stop testing if either a BF > 10 in favor of the hypothesis of a negative condition effect, a BF > 3 against the hypothesis, or at an N=30/condition (N=60 total). Note, we report the final N = 60 here. 

3. Next, we will run a followup regression including a main effect of age (in months, centered) and an interaction of `condition * age_m`.

This analysis is repeated below first for V1 (puzzles visible) and then for V2 (puzzles obscured)

Finally, in post-hoc, non-preregistered analyses, we pool the datasets across V1 and V2 to look at condition effects and `condition * age_m` interaction.

# Experiment V1: Puzzles Visible (N = 60)

## Load and Prepare Data

```{r}
setwd('/Users/Kat/Library/Mobile Documents/com~apple~CloudDocs/EALS/Code/EALS final repo/data/exp1/')
rm(list=ls())

# Read in data uploaded to github under folder "exp1"

#  N = 60 Sequential Sampling Final Sample for V1
eals1_v1_n60_df <- read_csv('EALS_Study1_V1_Data_n60.csv')

```


## Puzzle choice counts by condition in V1

How many participants chose harder/larger-reward puzzle per condition?

```{r}
#how many participants chose harder/larger-reward puzzle per condition?
eals1_v1_n60_df %>% count(condition, puzzle_harder)

```

## Mean of choice harder/larger-reward puzzle per condition in V1

```{r}
#Mean per condition 
eals1_v1_n60_df %>% group_by(condition) %>% summarise(mean_harder = mean(puzzle_harder, na.rm = TRUE))
```

## Logistic regression: condition effect (reliable = reference) in V1

Here we are predicting harder/larger reward puzzle choice with reliable as reference group (so, asking if there is a negative effect of unreliable on choice harder puzzle, as preregistered.) 

```{r}
#Logistic regression predicting harder/larger reward puzzle choice
eals1_mod_v1_n60 <- glm(puzzle_harder ~ condition, family = "binomial", data = eals1_v1_n60_df)

summary(eals1_mod_v1_n60)
```

## Odds ratio: condition effect in V1

```{r}
round(exp(coef(eals1_mod_v1_n60)),  digits = 2)

```

In V1 (N=60), compared to the reliable condition, those children in the unreliable condition have ~.32 times odds (harder to conceptualize because fraction) of choosing the harder/larger-reward puzzle.

We can also flip so unreliable is reference group, which makes the odds ratios easier to interpret (i.e., odds ratio will be >1 for effect of reliable on choice of puzzle harder).


## Logistic regression: flipped reference (unreliable = reference)

```{r}
#Logistic regression predicting harder/larger reward puzzle choice - flipped
eals1_mod_v1_n60_flip <- glm(puzzle_harder ~ relevel(as.factor(condition), ref = "Unreliable"), family = "binomial", data = eals1_v1_n60_df)

summary(eals1_mod_v1_n60_flip)
```

Next, we will compute the odds ratio for effect of reliable:

```{r}
round(exp(coef(eals1_mod_v1_n60_flip)),  digits = 2)
#this shows us the reliable odds ratio, easier to flip so unreliable is reference so odds ratio will be >1 for effect of reliable
```

In V1 (N=60), compared to unreliable, those children in the reliable condition have 3.14 times higher odds of choosing harder/larger reward puzzle (same thing, so saying it this way is easier to understand (= ~1/.32)

Since this is easier to interpret, we will report the flipped model odds ratio.

## 95% Confidence Intervals (flipped model) in V1

```{r}
#95% confidence intervals
round(exp(confint(eals1_mod_v1_n60_flip)),  digits = 2)
#1/exp(confint(eals1_mod_v1_n60)) #just noting that this is the same as inverting the confidence intervals of the original model
```

Next, we will compute the Bayes factor on the original (non-flipped) logistic regression with reliable as the reference group, because this is our pre-registered approach.

## Computing Bayes factor on logistic regression in V1

```{r}
#Bayes Factor
#see https://cran.r-project.org/web/packages/BFpack/vignettes/vignette_BFpack.html for example

eals1_BF_mod_v1_n60 <- BF(eals1_mod_v1_n60, hypothesis = "condition < 0; condition = 0", complement = FALSE)

summary(eals1_BF_mod_v1_n60)
```

Note that in the BFpack model output, the null hypothesis \( H_0: \beta = 0 \) is labeled `"H2"` by default. For consistency with our reporting conventions, we relabel:

- \( H_0: \beta = 0 \): no effect of condition (null)
- \( H_1: \beta < 0 \): preregistered directional hypothesis (Unreliable < Reliable)

The Bayes factor indicates that the data are **2.18 times more likely** under \( H_1 \) than under \( H_0 \), providing modest support for our preregistered prediction but below preregistered threshold of BF > 3 for interpreting significance.

## Age covariate and distribution in V1

```{r}
#Age distribution and interaction

#create centered age variable 
eals1_v1_n60_df$age_m_cen = eals1_v1_n60_df$age_m #duplicate original so can still look at score without center
eals1_v1_n60_df$age_m_cen = eals1_v1_n60_df$age_m - mean(eals1_v1_n60_df$age_m)

#distribution of age 
#vertical box plot by group
boxplot(age_m ~ condition, data = eals1_v1_n60_df, col = "white")

# Points
stripchart(age_m ~ condition,
           data = eals1_v1_n60_df,
           method = "jitter",
           pch = 19,
           col = 2:4,
           vertical = TRUE,
           add = TRUE)
```


## Is there a difference in age across conditions in V1?

```{r}
#test difference in age across conditions
t.test(age_m_cen ~ condition, data = eals1_v1_n60_df)
```

We find no significant difference in age between reliable and unreliable help conditions.

## Logistic regression with age-by-condition interaction + 95% confidence intervals in V1

```{r}
#logistic regression condition age and condition - interaction
eals1_mod_v1_n60_ageint <- glm(puzzle_harder ~ condition + age_m_cen + condition*age_m_cen, family = "binomial", data = eals1_v1_n60_df)

summary(eals1_mod_v1_n60_ageint)
round(confint(eals1_mod_v1_n60_ageint),  digits = 2)
```

## Computing Bayes factor on logistic regression with age-by-condition interaction in V1

```{r}
#Bayes Factor
eals1_BF_mod_v1_n60_ageint <- BF(eals1_mod_v1_n60_ageint, hypothesis = "conditionUnreliable < 0; conditionUnreliable = 0", complement = FALSE)

summary(eals1_BF_mod_v1_n60_ageint)
```

The BF for a negative effect of unreliable condition on choice of puzzle harder is 1.32 in the model with age-by-condition interaction included. Since the interaction wasn't significant, we chose to run the model for the main effects.

## Logistic regression with age and condition main effects + 95% confidence intervals in V1

```{r}
#logistic regression condition age and condition - main effects
eals1_mod_v1_n60_agemain <- glm(puzzle_harder ~ condition + age_m_cen, family = "binomial", data = eals1_v1_n60_df)

summary(eals1_mod_v1_n60_agemain)
round(confint(eals1_mod_v1_n60_agemain),  digits = 2)
```

## Computing Bayes factor on logistic regression with age and condition main effects in V1

```{r}
#Bayes Factor
eals1_BF_mod_v1_n60_agemain <- BF(eals1_mod_v1_n60_agemain, hypothesis = "conditionUnreliable < 0; conditionUnreliable = 0", complement = FALSE)

summary(eals1_BF_mod_v1_n60_agemain)
```


In the additive model (condition + age), both main effects were statistically significant. The Bayes factor for the preregistered hypothesis of a negative condition effect was \( \text{BF}_{10} = 2.37 \), providing modest evidence in favor of \( H_1 \).

While the age-by-condition interaction term was not statistically significant, it remains possible that an interaction exists but was not detected due to limited power. We revisit this question in the pooled analysis across V1 and V2 (N = 120).


# Experiment V2: Puzzles Obscured (N = 60)

## Load and Prepare Data in V2

```{r}
setwd('/Users/Kat/Library/Mobile Documents/com~apple~CloudDocs/EALS/Code/EALS final repo/data/exp1/')
eals1_v2_n60_df <- read_csv('EALS_Study1_V2_Data_N60.csv')

```


## Puzzle choice counts by condition in V2

How many participants chose harder/larger-reward puzzle per condition?

```{r}
#how many participants chose harder/larger-reward puzzle per condition?
eals1_v2_n60_df %>% count(condition, puzzle_harder)

```

## Mean of choice harder/larger-reward puzzle per condition  in V2

```{r}
#Mean per condition 
eals1_v2_n60_df %>% group_by(condition) %>% summarise(mean_harder = mean(puzzle_harder, na.rm = TRUE))

```

## Logistic regression: condition effect (reliable = reference) in V2

Here we are predicting harder/larger reward puzzle choice with reliable as reference group (so, asking if there is a negative effect of unreliable on choice harder puzzle, as preregistered.) 

```{r}
#Logistic regression predicting harder/larger reward puzzle choice
eals1_mod_v2_n60 <- glm(puzzle_harder ~ condition, family = "binomial", data = eals1_v2_n60_df)
summary(eals1_mod_v2_n60)

```

## Odds ratio: condition effect in V2

```{r}
round(exp(coef(eals1_mod_v2_n60)),  digits = 2)

```

In V2 (N=60), compared to the reliable condition, those children in the unreliable condition have ~.29 times odds (harder to conceptualize because fraction) of choosing the harder/larger-reward puzzle. We will reanalyze with unreliable as the reference group so we get more interpretable odds ratio.

## Logistic regression: flipped reference (unreliable = reference) in V2

```{r}
#Logistic regression predicting harder/larger reward puzzle choice - flipped
eals1_mod_v2_n60_flip <- glm(puzzle_harder ~ relevel(as.factor(condition), ref = "Unreliable"), family = "binomial", data = eals1_v2_n60_df)

summary(eals1_mod_v2_n60_flip)
```

Next, we will compute the odds ratio for effect of reliable:

```{r}
round(exp(coef(eals1_mod_v2_n60_flip)),  digits = 2)
#this shows us the reliable odds ratio, easier to flip so unreliable is reference so odds ratio will be >1 for effect of reliable
```


In V2 (N=60), compared to unreliable, those children in the reliable condition have 3.45 times higher odds of choosing harder/larger reward puzzle (same thing, so saying it this way is easier to understand = ~1/.29)

## 95% Confidence Intervals (flipped model) in V2

```{r}
#95% confidence intervals
round(exp(confint(eals1_mod_v2_n60_flip)),  digits = 2)
#1/exp(confint(eals1_mod_v2_n60)) #just noting that this is the same as inverting the confidence intervals of the original model
```

Next, we will compute the Bayes factor on the original (non-flipped) logistic regression with reliable as the reference group, because this is our pre-registered approach.

## Computing Bayes factor on logistic regression in V2

```{r}
#Bayes Factor
#see https://cran.r-project.org/web/packages/BFpack/vignettes/vignette_BFpack.html for example

eals1_BF_mod_v2_n60 <- BF(eals1_mod_v2_n60, hypothesis = "condition < 0; condition = 0", complement = FALSE)

summary(eals1_BF_mod_v2_n60)
```

- \( H_0: \beta = 0 \): no effect of condition (null)
- \( H_1: \beta < 0 \): preregistered directional hypothesis (Unreliable < Reliable)

The Bayes factor indicates that the data are **3.5 times more likely** under \( H_1 \) than under \( H_0 \), providing weak but significant support for our preregistered prediction (above preregistered threshold of BF > 3 for interpreting significance).

## Age covariate and distribution in V2

```{r}
#Age distribution and interaction

#create centered age variable 
eals1_v2_n60_df$age_m_cen = eals1_v2_n60_df$age_m #duplicate original so can still look at score without center
eals1_v2_n60_df$age_m_cen = eals1_v2_n60_df$age_m - mean(eals1_v2_n60_df$age_m)

#distribution of age 
#vertical box plot by group
boxplot(age_m ~ condition, data = eals1_v2_n60_df, col = "white")

# Points
stripchart(age_m ~ condition,
           data = eals1_v2_n60_df,
           method = "jitter",
           pch = 19,
           col = 2:4,
           vertical = TRUE,
           add = TRUE)
```


## Is there a difference in age across conditions in V2?

```{r}
#is there a difference in age across conditions?
t.test(age_m_cen ~ condition, data = eals1_v2_n60_df)
```

We find no difference between conditions in age for V2. Let's look at the age-by-condition interaction in this sample.

## Logistic regression with age-by-condition interaction + 95% confidence intervals in V2

```{r}
#logistic regression condition age and condition - interaction
eals1_mod_v2_n60_ageint <- glm(puzzle_harder ~ condition + age_m_cen + condition*age_m_cen, family = "binomial", data = eals1_v2_n60_df)

summary(eals1_mod_v2_n60_ageint)
round(confint(eals1_mod_v2_n60_ageint),  digits = 2)
```

## Computing Bayes factor on logistic regression with age-by-condition interaction in V2

```{r}
#Bayes Factor
eals1_BF_mod_v2_n60_ageint <- BF(eals1_mod_v2_n60_ageint, hypothesis = "conditionUnreliable < 0; conditionUnreliable = 0", complement = FALSE)

summary(eals1_BF_mod_v2_n60_ageint)
#check specification of BF with interaction model
```

Again, we find the interaction term is not significant. The BF for a negative effect of unreliable condition on choice of puzzle harder is 3.86 in the model with age-by-condition interaction included.  We'll look at the main effects of age and condition next.

## Logistic regression with age and condition main effects + 95% confidence intervals in V2

```{r}
#logistic regression condition age and condition - main effects
eals1_mod_v2_n60_agemain <- glm(puzzle_harder ~ condition + age_m_cen, family = "binomial", data = eals1_v2_n60_df)
summary(eals1_mod_v2_n60_agemain)
round(confint(eals1_mod_v2_n60_agemain),  digits = 2)
```

## Computing Bayes factor on logistic regression with age and condition main effects in V2

```{r}
#Bayes Factor
eals1_BF_mod_v2_n60_agemain <- BF(eals1_mod_v2_n60_agemain, hypothesis = "conditionUnreliable < 0; conditionUnreliable = 0", complement = FALSE)
summary(eals1_BF_mod_v2_n60_agemain)
```

In the additive model (condition + age), both main effects were statistically significant. The Bayes factor for the preregistered hypothesis of a negative condition effect was \( \text{BF}_{10} = 4.35 \), providing weak but significant evidence in favor of \( H_1 \).

# Pooled Results (V1 Puzzles Visible + V2 Obscured, N = 120)

For post-hoc, non-preregistered analyses, let's look at the pooled results across study 1 and 2

```{r}
# Concatenate the dataframes
eals1_pooled_n120_df <- rbind(eals1_v1_n60_df, eals1_v2_n60_df)
```

## How many participants chose harder/larger-reward puzzle per condition in pooled data (N=120)?

```{r}
#Count puzzle choice by condition pooled
eals1_pooled_n120_df %>% group_by(condition, puzzle_harder) %>% summarise(count = n_distinct(participant_video_id))
```


## Logistic regression: condition effect (reliable = reference) in pooled (N = 120)

Here we predicting harder/larger reward puzzle choice with reliable as reference group (so asking if there is a negative effect of unreliable on choice harder puzzle). We'll also add experiment V1/V2 as a fixed effect.

```{r}
#Logistic regression predicting harder/larger reward puzzle choice
eals1_mod_pooled_n120 <- glm(puzzle_harder ~ condition + experiment, family = "binomial", data = eals1_pooled_n120_df)

summary(eals1_mod_pooled_n120)
```

## Odds ratio: condition effect in pooled (N = 120)

```{r}
round(exp(coef(eals1_mod_pooled_n120)),  digits = 2)

```

Compared to the reliable condition, those children in the unreliable condition have ~.30 times odds (harder to conceptualize because fraction) of choosing the harder/larger-reward puzzle. We will reanalyze with unreliable as the reference group so we get more interpretable odds ratio. Those in experiment V2 have ~ .60 times odds of choosing harder/puzzle. Although experiment is not a significant predictor, note this direction makes sense if fewer participants choose the harder puzzle when it was obscured.

## Logistic regression: flipped reference (unreliable = reference) in pooled (N = 120)

```{r}
#Logistic regression predicting harder/larger reward puzzle choice - flipped
eals1_mod_pooled_n120_flip <- glm(puzzle_harder ~ relevel(as.factor(condition), ref = "Unreliable") + relevel(as.factor(experiment), ref = "2"), family = "binomial", data = eals1_pooled_n120_df)
summary(eals1_mod_pooled_n120_flip)
```

Next, we will compute the odds ratio for effect of reliable:

```{r}
round(exp(coef(eals1_mod_pooled_n120_flip)),  digits = 2)
#this shows us the reliable odds ratio, easier to flip so unreliable is reference so odds ratio will be >1 for effect of reliable
```

In the pooled data (N = 120), compared to unreliable, those children in the reliable condition have 3.30 times higher odds of choosing harder/larger reward puzzle (same thing, so say it this way is easier to understand = ~1/.30).

## 95% Confidence Intervals (flipped model) in pooled (N = 120)

```{r}
#95% confidence intervals
round(exp(confint(eals1_mod_pooled_n120_flip)),  digits = 2)
#1/exp(confint(eals1_mod_pooled_n120)) #just noting that this is the same as inverting the confidence intervals of the original model
```

## Computing Bayes factor on logistic regression in pooled (N = 120)

```{r}
#Bayes Factor
#see https://cran.r-project.org/web/packages/BFpack/vignettes/vignette_BFpack.html for example

eals1_BF_mod_pooled_n120 <- BF(eals1_mod_pooled_n120, hypothesis = "condition < 0; condition = 0", complement = FALSE)
summary(eals1_BF_mod_pooled_n120)
```

- \( H_0: \beta = 0 \): no effect of condition (null)
- \( H_1: \beta < 0 \): preregistered directional hypothesis (Unreliable < Reliable)

As expected, we find a higher BF for our hypothesis (H1) of a negative effect of unreliable on choice of harder/larger-reward puzzle over the null hypothesis (H0) because we doubled our sample size. The Bayes factor indicates that the data are **21.38 times more likely** under \( H_1 \) than under \( H_0 \)

## Age covariate and distribution in pooled (N = 120)

```{r}
#recompute age over pooled participants
eals1_pooled_n120_df$age_m_cen = eals1_pooled_n120_df$age_m - mean(eals1_pooled_n120_df$age_m)

# Vertical box plot by group
boxplot(age_m ~ condition, data = eals1_pooled_n120_df, col = "white")

# Points
stripchart(age_m ~ condition,
           data = eals1_pooled_n120_df,
           method = "jitter",
           pch = 19,
           col = 2:4,
           vertical = TRUE,
           add = TRUE)
```

## Is there a difference in age across conditions in pooled (N = 120)?

```{r}
#test difference in age across conditions
t.test(age_m_cen ~ condition, data = eals1_pooled_n120_df) 
```

We find no difference in age by condition in the pooled dataset.

Next, we ask if we find a significant interaction of age-by-condition on choice of harder puzzle in the pooled data:

## Logistic regression - interaction age by condition with experiment as fixed effect in pooled (N = 120)

```{r}
#logistic regression - interaction
eals1_mod_pooled_n120_ageint <- glm(puzzle_harder ~ condition + age_m_cen + experiment + condition*age_m_cen, family = "binomial", data = eals1_pooled_n120_df)

summary(eals1_mod_pooled_n120_ageint)
round(confint(eals1_mod_pooled_n120_ageint),  digits = 2)
```

Here, we find the interaction of age-by-condition is not a significant predictor of puzzle choice in the pooled data. Age and unreliable condition remain significant predictors.
